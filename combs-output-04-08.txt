Total combinations to train: 4

=== Training combination 1/4 ===
N_samples: 30000, Steps: 25000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
Downloading from: https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/pt/pt_PT/tugão/medium/pt_PT-tugão-medium.onnx
Saving to: models/pt_PT-tugão-medium.onnx
✓ Successfully downloaded pt_PT-tugão-medium.onnx
Downloading from: https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/pt/pt_PT/tugão/medium/pt_PT-tugão-medium.onnx.json
Saving to: models/pt_PT-tugão-medium.onnx.json
✓ Successfully downloaded pt_PT-tugão-medium.onnx.json
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
INFO:piper.download:Downloaded models/es_MX-claude-high.onnx.json (https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/es/es_MX/claude/high/es_MX-claude-high.onnx.json)
INFO:piper.download:Downloaded models/es_MX-claude-high.onnx (https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/es/es_MX/claude/high/es_MX-claude-high.onnx)
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
INFO:piper.download:Downloaded models/pt_BR-cadu-medium.onnx (https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/pt/pt_BR/cadu/medium/pt_BR-cadu-medium.onnx)
INFO:piper.download:Downloaded models/pt_BR-cadu-medium.onnx.json (https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/pt/pt_BR/cadu/medium/pt_BR-cadu-medium.onnx.json)
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
INFO:piper.download:Downloaded models/pt_BR-faber-medium.onnx (https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx)
INFO:piper.download:Downloaded models/pt_BR-faber-medium.onnx.json (https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx.json)
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
INFO:piper_gen:Pre-generating random parameters...
INFO:piper_gen:Starting generation of 30000 samples using GPU...
Generating samples: 100%|█████████████████| 30000/30000 [30:23<00:00, 16.45it/s]
INFO:piper_gen:Generation complete! Successful: 30000, Failed: 0
INFO:root:##################################################
Generating positive clips for testing
##################################################
INFO:piper_gen:Pre-generating random parameters...
INFO:piper_gen:Starting generation of 2000 samples using GPU...
Generating samples: 100%|███████████████████| 2000/2000 [00:42<00:00, 47.24it/s]
INFO:piper_gen:Generation complete! Successful: 2000, Failed: 0
INFO:root:##################################################
Generating negative clips for training
##################################################
WARNING:root:Downloading phonemizer model from DeepPhonemizer library...
/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
WARNING:root:The word 'Clãriss' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.
WARNING:root:Phones for 'Clãriss': [K][L][R][IH][S]
INFO:generate_samples:Successfully loaded the model
INFO:generate_samples:Done
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:The word 'Clãriss' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.
WARNING:root:Phones for 'Clãriss': [K][L][R][IH][S]
INFO:generate_samples:Successfully loaded the model
INFO:generate_samples:Done
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|██████████████████▉| 1874/1875 [03:48<00:00,  8.19it/s]
Trimming empty rows: 30it [00:00, 88.84it/s]                                    
Computing features: 100%|██████████████████▉| 1874/1875 [03:49<00:00,  8.17it/s]
Trimming empty rows: 30it [00:00, 101.03it/s]                                   
Computing features:  99%|████████████████████▊| 124/125 [00:14<00:00,  8.45it/s]
Trimming empty rows: 2it [00:00, 114.65it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:14<00:00,  8.29it/s]
Trimming empty rows: 2it [00:00, 107.19it/s]                                    
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 24999/25000 [05:52<00:00, 70.93it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2499/2500.0 [02:49<00:00, 14.74it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2499/2500.0 [02:54<00:00, 14.36it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.7599999904632568
Final Model Recall: 0.5210000276565552
Final Model False Positives per Hour: 0.7079645991325378
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n30000_s25000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754303461.138106 1085487 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754303461.144512 1085487 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754303461.161179 1085487 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754303461.161204 1085487 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754303461.161209 1085487 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754303461.161213 1085487 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  132266855613072: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  132269017819728: TensorSpec(shape=(), dtype=tf.float32, name=None)
  132266855616336: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  132266855614224: TensorSpec(shape=(), dtype=tf.float32, name=None)
  132266855619216: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  132266855617680: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  132266855616720: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  132266855617296: TensorSpec(shape=(), dtype=tf.float32, name=None)
  132266855617104: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  132266855619792: TensorSpec(shape=(), dtype=tf.float32, name=None)
  132266855618832: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  132266855617488: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  132266855618448: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  132266855616912: TensorSpec(shape=(), dtype=tf.float32, name=None)
  132266855616528: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754303465.950576 1085487 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754303465.950965 1085487 single_machine.cc:374] Starting new session
W0000 00:00:1754303466.095347 1085487 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754303466.095393 1085487 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754303466.156658 1085487 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754303466.156975 1085487 single_machine.cc:374] Starting new session
W0000 00:00:1754303466.302654 1085487 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754303466.302702 1085487 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 2/4 ===
N_samples: 35000, Steps: 25000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
INFO:piper_gen:Pre-generating random parameters...
INFO:piper_gen:Starting generation of 5000 samples using GPU...
Generating samples: 100%|███████████████████| 5000/5000 [23:15<00:00,  3.58it/s]
INFO:piper_gen:Generation complete! Successful: 5000, Failed: 0
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
WARNING:root:The word 'Clãriss' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.
WARNING:root:Phones for 'Clãriss': [K][L][R][IH][S]
INFO:generate_samples:Successfully loaded the model
INFO:generate_samples:Done
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|███████████████████| 2187/2187 [04:16<00:00,  8.51it/s]
Trimming empty rows: 35it [00:00, 104.71it/s]                                   
Computing features: 100%|███████████████████| 2187/2187 [04:41<00:00,  7.76it/s]
Trimming empty rows: 35it [00:00, 42.63it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:12<00:00,  9.85it/s]
Trimming empty rows: 2it [00:00, 35.71it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:13<00:00,  9.29it/s]
Trimming empty rows: 2it [00:00, 85.07it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 24999/25000 [06:02<00:00, 68.89it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2499/2500.0 [02:51<00:00, 14.56it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2499/2500.0 [03:20<00:00, 12.47it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.7112500071525574
Final Model Recall: 0.4235000014305115
Final Model False Positives per Hour: 0.0
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n35000_s25000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754306400.573159 1625570 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754306400.580605 1625570 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754306400.598204 1625570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754306400.598232 1625570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754306400.598242 1625570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754306400.598246 1625570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  140156354136208: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  140156354136592: TensorSpec(shape=(), dtype=tf.float32, name=None)
  140156354137936: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  140156354136400: TensorSpec(shape=(), dtype=tf.float32, name=None)
  140156354140816: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  140156354139280: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  140156354138320: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  140156354138896: TensorSpec(shape=(), dtype=tf.float32, name=None)
  140156354138704: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  140156354141392: TensorSpec(shape=(), dtype=tf.float32, name=None)
  140156354140432: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  140156354139088: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  140156354140048: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  140156354138512: TensorSpec(shape=(), dtype=tf.float32, name=None)
  140156354138128: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754306405.968471 1625570 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754306405.968892 1625570 single_machine.cc:374] Starting new session
W0000 00:00:1754306406.127294 1625570 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754306406.127341 1625570 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754306406.192652 1625570 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754306406.192955 1625570 single_machine.cc:374] Starting new session
W0000 00:00:1754306406.336312 1625570 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754306406.336359 1625570 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 3/4 ===
N_samples: 45000, Steps: 25000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
INFO:piper_gen:Pre-generating random parameters...
INFO:piper_gen:Starting generation of 10000 samples using GPU...
Generating samples: 100%|█████████████████| 10000/10000 [24:42<00:00,  6.75it/s]
INFO:piper_gen:Generation complete! Successful: 10000, Failed: 0
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
WARNING:root:The word 'Clãriss' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.
WARNING:root:Phones for 'Clãriss': [K][L][R][IH][S]
INFO:generate_samples:Successfully loaded the model
INFO:generate_samples:Done
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|███████████████████| 2812/2812 [05:39<00:00,  8.29it/s]
Trimming empty rows: 44it [00:00, 91.18it/s]                                    
Computing features: 100%|███████████████████| 2812/2812 [05:52<00:00,  7.98it/s]
Trimming empty rows: 44it [00:00, 90.81it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:14<00:00,  8.74it/s]
Trimming empty rows: 2it [00:00, 33.77it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:15<00:00,  8.20it/s]
Trimming empty rows: 2it [00:00, 31.12it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 24999/25000 [06:00<00:00, 69.41it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2499/2500.0 [02:55<00:00, 14.21it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2499/2500.0 [02:58<00:00, 14.00it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.5857499837875366
Final Model Recall: 0.17149999737739563
Final Model False Positives per Hour: 0.0
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n45000_s25000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754309656.521734 2311029 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754309656.528400 2311029 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754309656.544452 2311029 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754309656.544489 2311029 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754309656.544493 2311029 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754309656.544497 2311029 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  138833095264400: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  138833095264784: TensorSpec(shape=(), dtype=tf.float32, name=None)
  138833095266128: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  138833095264592: TensorSpec(shape=(), dtype=tf.float32, name=None)
  138833095269008: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  138833095267472: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  138833095266512: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  138833095267088: TensorSpec(shape=(), dtype=tf.float32, name=None)
  138833095266896: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  138833095269584: TensorSpec(shape=(), dtype=tf.float32, name=None)
  138833095268624: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  138833095267280: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  138833095268240: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  138833095266704: TensorSpec(shape=(), dtype=tf.float32, name=None)
  138833095266320: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754309661.645726 2311029 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754309661.646106 2311029 single_machine.cc:374] Starting new session
W0000 00:00:1754309661.803081 2311029 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754309661.803124 2311029 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754309661.866396 2311029 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754309661.866731 2311029 single_machine.cc:374] Starting new session
W0000 00:00:1754309662.035109 2311029 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754309662.035153 2311029 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 4/4 ===
N_samples: 50000, Steps: 25000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
INFO:piper_gen:Pre-generating random parameters...
INFO:piper_gen:Starting generation of 5000 samples using GPU...
Generating samples: 100%|███████████████████| 5000/5000 [22:56<00:00,  3.63it/s]
INFO:piper_gen:Generation complete! Successful: 5000, Failed: 0
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
WARNING:root:The word 'Clãriss' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.
WARNING:root:Phones for 'Clãriss': [K][L][R][IH][S]
INFO:generate_samples:Successfully loaded the model
INFO:generate_samples:Done
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|██████████████████▉| 3124/3125 [06:16<00:00,  8.31it/s]
Trimming empty rows: 49it [00:00, 95.31it/s]                                    
Computing features: 100%|██████████████████▉| 3124/3125 [06:32<00:00,  7.96it/s]
Trimming empty rows: 49it [00:01, 36.94it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:17<00:00,  7.13it/s]
Trimming empty rows: 2it [00:00, 34.06it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:14<00:00,  8.49it/s]
Trimming empty rows: 2it [00:00, 32.40it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 24999/25000 [06:00<00:00, 69.27it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2499/2500.0 [02:43<00:00, 15.26it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2499/2500.0 [02:59<00:00, 13.92it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.6727499961853027
Final Model Recall: 0.34549999237060547
Final Model False Positives per Hour: 0.0
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n50000_s25000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754312803.390646 3046273 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754312803.397221 3046273 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754312803.413571 3046273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754312803.413596 3046273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754312803.413600 3046273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754312803.413604 3046273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  124442123567760: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  124442144991824: TensorSpec(shape=(), dtype=tf.float32, name=None)
  124442123571024: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  124442123568912: TensorSpec(shape=(), dtype=tf.float32, name=None)
  124442123573904: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  124442123572368: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  124442123571408: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  124442123571984: TensorSpec(shape=(), dtype=tf.float32, name=None)
  124442123571792: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  124442123574480: TensorSpec(shape=(), dtype=tf.float32, name=None)
  124442123573520: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  124442123572176: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  124442123573136: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  124442123571600: TensorSpec(shape=(), dtype=tf.float32, name=None)
  124442123571216: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754312808.167457 3046273 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754312808.167852 3046273 single_machine.cc:374] Starting new session
W0000 00:00:1754312808.335191 3046273 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754312808.335235 3046273 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754312808.397994 3046273 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754312808.398320 3046273 single_machine.cc:374] Starting new session
W0000 00:00:1754312808.551877 3046273 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754312808.551923 3046273 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!