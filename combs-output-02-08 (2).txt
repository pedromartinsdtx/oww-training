Total combinations to train: 12

=== Training combination 1/12 ===
N_samples: 40000, Steps: 30000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
INFO:piper_gen:Pre-generating random parameters...
INFO:piper_gen:Starting generation of 40000 samples using GPU...
Generating samples: 100%|█████████████████| 40000/40000 [34:54<00:00, 19.10it/s]
INFO:piper_gen:Generation complete! Successful: 40000, Failed: 0
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
WARNING:root:The word 'Clãriss' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.
WARNING:root:Phones for 'Clãriss': [K][L][R][IH][S]
INFO:generate_samples:Successfully loaded the model
INFO:generate_samples:Done
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|██████████████████▉| 2499/2500 [05:13<00:00,  7.98it/s]
Trimming empty rows: 40it [00:00, 87.47it/s]                                    
Computing features: 100%|██████████████████▉| 2499/2500 [05:41<00:00,  7.31it/s]
Trimming empty rows: 40it [00:00, 45.58it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:16<00:00,  7.47it/s]
Trimming empty rows: 2it [00:00, 37.53it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:15<00:00,  7.89it/s]
Trimming empty rows: 2it [00:00, 24.73it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 29999/30000 [06:34<00:00, 76.06it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2999/3000.0 [03:07<00:00, 16.03it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2999/3000.0 [03:04<00:00, 16.23it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.7770000100135803
Final Model Recall: 0.5540000200271606
Final Model False Positives per Hour: 0.17699114978313446
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n40000_s30000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754158341.274732 2440031 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754158341.281306 2440031 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754158341.297578 2440031 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754158341.297609 2440031 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754158341.297613 2440031 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754158341.297616 2440031 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  127086258979472: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  127086261529168: TensorSpec(shape=(), dtype=tf.float32, name=None)
  127086258982736: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  127086258980624: TensorSpec(shape=(), dtype=tf.float32, name=None)
  127086258985616: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  127086258984080: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  127086258983120: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  127086258983696: TensorSpec(shape=(), dtype=tf.float32, name=None)
  127086258983504: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  127086258986192: TensorSpec(shape=(), dtype=tf.float32, name=None)
  127086258985232: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  127086258983888: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  127086258984848: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  127086258983312: TensorSpec(shape=(), dtype=tf.float32, name=None)
  127086258982928: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754158346.578256 2440031 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754158346.578638 2440031 single_machine.cc:374] Starting new session
W0000 00:00:1754158346.745181 2440031 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754158346.745217 2440031 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754158346.808768 2440031 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754158346.809098 2440031 single_machine.cc:374] Starting new session
W0000 00:00:1754158347.000208 2440031 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754158347.000258 2440031 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 2/12 ===
N_samples: 40000, Steps: 35000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
WARNING:root:Skipping generation of positive clips for training, as ~40000 already exist
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
WARNING:root:Skipping generation of negative clips for training, as ~40000 already exist
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|██████████████████▉| 2499/2500 [05:57<00:00,  6.98it/s]
Trimming empty rows: 40it [00:00, 88.89it/s]                                    
Computing features: 100%|██████████████████▉| 2499/2500 [05:09<00:00,  8.09it/s]
Trimming empty rows: 40it [00:00, 44.24it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:18<00:00,  6.76it/s]
Trimming empty rows: 2it [00:00, 38.80it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:14<00:00,  8.31it/s]
Trimming empty rows: 2it [00:00, 39.97it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 34999/35000 [07:24<00:00, 78.67it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 3499/3500.0 [03:08<00:00, 18.60it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 3499/3500.0 [03:11<00:00, 18.26it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.628000020980835
Final Model Recall: 0.25600001215934753
Final Model False Positives per Hour: 0.08849557489156723
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n40000_s35000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754159955.131543 3067509 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754159955.137905 3067509 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754159955.154035 3067509 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754159955.154064 3067509 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754159955.154068 3067509 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754159955.154072 3067509 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  130870472788112: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  130870472788496: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130870472789840: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  130870472788304: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130870472792720: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130870472791184: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130870472790224: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  130870472790800: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130870472790608: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  130870472793296: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130870472792336: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130870472790992: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130870472791952: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  130870472790416: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130870472790032: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754159960.305767 3067509 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754159960.306189 3067509 single_machine.cc:374] Starting new session
W0000 00:00:1754159960.466105 3067509 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754159960.466152 3067509 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754159960.528840 3067509 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754159960.529156 3067509 single_machine.cc:374] Starting new session
W0000 00:00:1754159960.687128 3067509 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754159960.687175 3067509 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 3/12 ===
N_samples: 40000, Steps: 40000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
WARNING:root:Skipping generation of positive clips for training, as ~40000 already exist
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
WARNING:root:Skipping generation of negative clips for training, as ~40000 already exist
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|██████████████████▉| 2499/2500 [05:28<00:00,  7.60it/s]
Trimming empty rows: 40it [00:00, 84.42it/s]                                    
Computing features: 100%|██████████████████▉| 2499/2500 [05:28<00:00,  7.61it/s]
Trimming empty rows: 40it [00:00, 69.19it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:13<00:00,  8.93it/s]
Trimming empty rows: 2it [00:00, 34.24it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:16<00:00,  7.36it/s]
Trimming empty rows: 2it [00:00, 36.51it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 39999/40000 [07:57<00:00, 83.82it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 3999/4000.0 [03:14<00:00, 20.53it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 3999/4000.0 [03:12<00:00, 20.72it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.6622499823570251
Final Model Recall: 0.3244999945163727
Final Model False Positives per Hour: 0.0
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n40000_s40000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754161594.240124 3685244 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754161594.246473 3685244 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754161594.262377 3685244 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754161594.262411 3685244 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754161594.262415 3685244 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754161594.262419 3685244 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  130920186316944: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  130920186317328: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130920186318672: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  130920186317136: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130920186321552: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130920186320016: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130920186319056: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  130920186319632: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130920186319440: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  130920186322128: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130920186321168: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130920186319824: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130920186320784: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  130920186319248: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130920186318864: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754161599.200269 3685244 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754161599.200954 3685244 single_machine.cc:374] Starting new session
W0000 00:00:1754161599.368933 3685244 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754161599.368977 3685244 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754161599.433096 3685244 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754161599.433410 3685244 single_machine.cc:374] Starting new session
W0000 00:00:1754161599.586241 3685244 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754161599.586287 3685244 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 4/12 ===
N_samples: 40000, Steps: 50000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
WARNING:root:Skipping generation of positive clips for training, as ~40000 already exist
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
WARNING:root:Skipping generation of negative clips for training, as ~40000 already exist
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|██████████████████▉| 2499/2500 [05:25<00:00,  7.68it/s]
Trimming empty rows: 40it [00:00, 91.12it/s]                                    
Computing features: 100%|██████████████████▉| 2499/2500 [05:10<00:00,  8.05it/s]
Trimming empty rows: 40it [00:00, 65.47it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:15<00:00,  7.84it/s]
Trimming empty rows: 2it [00:00, 37.58it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:15<00:00,  7.95it/s]
Trimming empty rows: 2it [00:00, 44.59it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 49999/50000 [09:08<00:00, 91.17it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 4999/5000.0 [03:21<00:00, 24.76it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 4999/5000.0 [03:15<00:00, 25.51it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.6202499866485596
Final Model Recall: 0.24050000309944153
Final Model False Positives per Hour: 0.0
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n40000_s50000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754163294.321323   94835 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754163294.327810   94835 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754163294.343968   94835 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754163294.343999   94835 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754163294.344003   94835 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754163294.344006   94835 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  134568257685648: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  134568257686032: TensorSpec(shape=(), dtype=tf.float32, name=None)
  134568257687376: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  134568257685840: TensorSpec(shape=(), dtype=tf.float32, name=None)
  134568257690256: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  134568257688720: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  134568257687760: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  134568257688336: TensorSpec(shape=(), dtype=tf.float32, name=None)
  134568257688144: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  134568257690832: TensorSpec(shape=(), dtype=tf.float32, name=None)
  134568257689872: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  134568257688528: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  134568257689488: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  134568257687952: TensorSpec(shape=(), dtype=tf.float32, name=None)
  134568257687568: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754163299.171518   94835 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754163299.171925   94835 single_machine.cc:374] Starting new session
W0000 00:00:1754163299.326513   94835 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754163299.326558   94835 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754163299.388539   94835 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754163299.388846   94835 single_machine.cc:374] Starting new session
W0000 00:00:1754163299.543679   94835 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754163299.543729   94835 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

Total combinations to train: 8

Total combinations to train: 8

=== Training combination 1/8 ===
N_samples: 45000, Steps: 30000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
INFO:piper_gen:Pre-generating random parameters...
INFO:piper_gen:Starting generation of 4847 samples using GPU...
Generating samples: 100%|███████████████████| 4847/4847 [20:33<00:00,  3.93it/s]
INFO:piper_gen:Generation complete! Successful: 4847, Failed: 0
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
WARNING:root:The word 'Clãriss' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.
WARNING:root:Phones for 'Clãriss': [K][L][R][IH][S]
INFO:generate_samples:Successfully loaded the model
INFO:generate_samples:Done
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|███████████████████| 2812/2812 [06:22<00:00,  7.35it/s]
Trimming empty rows: 44it [00:00, 88.42it/s]                                    
Computing features: 100%|███████████████████| 2812/2812 [05:43<00:00,  8.18it/s]
Trimming empty rows: 44it [00:00, 49.81it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:15<00:00,  7.94it/s]
Trimming empty rows: 2it [00:00, 35.26it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:18<00:00,  6.82it/s]
Trimming empty rows: 2it [00:00, 33.62it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 29999/30000 [06:46<00:00, 73.81it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2999/3000.0 [03:08<00:00, 15.91it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 2999/3000.0 [03:05<00:00, 16.19it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.6894999742507935
Final Model Recall: 0.3790000081062317
Final Model False Positives per Hour: 0.0
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n45000_s30000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754168447.921336  777393 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754168447.927782  777393 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754168447.944223  777393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754168447.944250  777393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754168447.944254  777393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754168447.944258  777393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  130812977875088: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  130812977875472: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130812977876816: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  130812977875280: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130812977879696: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130812977878160: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130812977877200: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  130812977877776: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130812977877584: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  130812977880272: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130812977879312: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130812977877968: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  130812977878928: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  130812977877392: TensorSpec(shape=(), dtype=tf.float32, name=None)
  130812977877008: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754168452.956699  777393 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754168452.957075  777393 single_machine.cc:374] Starting new session
W0000 00:00:1754168453.115598  777393 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754168453.115646  777393 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754168453.178114  777393 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754168453.178478  777393 single_machine.cc:374] Starting new session
W0000 00:00:1754168453.337594  777393 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754168453.337640  777393 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 2/8 ===
N_samples: 45000, Steps: 35000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
WARNING:root:Skipping generation of positive clips for training, as ~45000 already exist
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
WARNING:root:Skipping generation of negative clips for training, as ~45000 already exist
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|███████████████████| 2812/2812 [05:44<00:00,  8.16it/s]
Trimming empty rows: 44it [00:00, 85.97it/s]                                    
Computing features: 100%|███████████████████| 2812/2812 [05:52<00:00,  7.99it/s]
Trimming empty rows: 44it [00:00, 44.44it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:14<00:00,  8.59it/s]
Trimming empty rows: 2it [00:00, 32.60it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:13<00:00,  9.26it/s]
Trimming empty rows: 2it [00:00, 40.03it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 34999/35000 [07:10<00:00, 81.30it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 3499/3500.0 [03:06<00:00, 18.80it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 3499/3500.0 [03:11<00:00, 18.24it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.7139999866485596
Final Model Recall: 0.42800000309944153
Final Model False Positives per Hour: 0.17699114978313446
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n45000_s35000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754170068.693414 1451779 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754170068.700285 1451779 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754170068.719877 1451779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754170068.719929 1451779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754170068.719933 1451779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754170068.719937 1451779 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  137287287669392: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  137287290202704: TensorSpec(shape=(), dtype=tf.float32, name=None)
  137287287672656: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  137287287670544: TensorSpec(shape=(), dtype=tf.float32, name=None)
  137287287675536: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  137287287674000: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  137287287673040: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  137287287673616: TensorSpec(shape=(), dtype=tf.float32, name=None)
  137287287673424: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  137287287676112: TensorSpec(shape=(), dtype=tf.float32, name=None)
  137287287675152: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  137287287673808: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  137287287674768: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  137287287673232: TensorSpec(shape=(), dtype=tf.float32, name=None)
  137287287672848: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754170073.844365 1451779 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754170073.844775 1451779 single_machine.cc:374] Starting new session
W0000 00:00:1754170074.087608 1451779 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754170074.087648 1451779 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754170074.148511 1451779 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754170074.148842 1451779 single_machine.cc:374] Starting new session
W0000 00:00:1754170074.349930 1451779 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754170074.349977 1451779 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 3/8 ===
N_samples: 45000, Steps: 40000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
WARNING:root:Skipping generation of positive clips for training, as ~45000 already exist
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
WARNING:root:Skipping generation of negative clips for training, as ~45000 already exist
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|███████████████████| 2812/2812 [06:02<00:00,  7.76it/s]
Trimming empty rows: 44it [00:00, 91.39it/s]                                    
Computing features: 100%|███████████████████| 2812/2812 [05:56<00:00,  7.88it/s]
Trimming empty rows: 44it [00:00, 44.90it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:17<00:00,  6.94it/s]
Trimming empty rows: 2it [00:00, 38.12it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:18<00:00,  6.69it/s]
Trimming empty rows: 2it [00:00, 37.68it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 39999/40000 [07:46<00:00, 85.82it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 3999/4000.0 [03:11<00:00, 20.93it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 3999/4000.0 [03:13<00:00, 20.71it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.7024999856948853
Final Model Recall: 0.4050000011920929
Final Model False Positives per Hour: 0.08849557489156723
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n45000_s40000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754171759.951676 2142080 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754171759.958288 2142080 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754171759.974773 2142080 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754171759.974802 2142080 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754171759.974805 2142080 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754171759.974809 2142080 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  125274531514512: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  125274531514896: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125274531516240: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  125274531514704: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125274531519120: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  125274531517584: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  125274531516624: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  125274531517200: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125274531517008: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  125274531519696: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125274531518736: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  125274531517392: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  125274531518352: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  125274531516816: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125274531516432: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754171764.891225 2142080 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754171764.891635 2142080 single_machine.cc:374] Starting new session
W0000 00:00:1754171765.066179 2142080 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754171765.066226 2142080 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754171765.132734 2142080 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754171765.133069 2142080 single_machine.cc:374] Starting new session
W0000 00:00:1754171765.311376 2142080 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754171765.311425 2142080 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 4/8 ===
N_samples: 45000, Steps: 50000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
WARNING:root:Skipping generation of positive clips for training, as ~45000 already exist
INFO:root:##################################################
Generating positive clips for testing
##################################################
WARNING:root:Skipping generation of positive clips testing, as ~2000 already exist
INFO:root:##################################################
Generating negative clips for training
##################################################
WARNING:root:Skipping generation of negative clips for training, as ~45000 already exist
INFO:root:##################################################
Generating negative clips for testing
##################################################
WARNING:root:Skipping generation of negative clips for testing, as ~2000 already exist
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Computing openwakeword features for generated samples
##################################################
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = BandStopFilter(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddBackgroundNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Compose(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/opt/conda/lib/python3.11/site-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32
  warnings.warn(
Computing features: 100%|███████████████████| 2812/2812 [06:25<00:00,  7.30it/s]
Trimming empty rows: 44it [00:00, 85.34it/s]                                    
Computing features: 100%|███████████████████| 2812/2812 [05:40<00:00,  8.26it/s]
Trimming empty rows: 44it [00:00, 66.71it/s]                                    
Computing features:  99%|████████████████████▊| 124/125 [00:15<00:00,  7.90it/s]
Trimming empty rows: 2it [00:00, 35.60it/s]                                     
Computing features:  99%|████████████████████▊| 124/125 [00:13<00:00,  9.13it/s]
Trimming empty rows: 2it [00:00, 37.37it/s]                                     
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
INFO:root:##################################################
Starting training sequence 1...
##################################################
Training: 100%|██████████████████████████▉| 49999/50000 [09:00<00:00, 92.43it/s]
INFO:root:##################################################
Starting training sequence 2...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 4999/5000.0 [03:17<00:00, 25.36it/s]
INFO:root:##################################################
Starting training sequence 3...
##################################################
INFO:root:Increasing weight on negative examples to reduce false positives...
Training: 100%|██████████████████████████▉| 4999/5000.0 [03:22<00:00, 24.72it/s]
INFO:root:Merging checkpoints above the 90th percentile into single model...
INFO:root:
################
Final Model Accuracy: 0.7459999918937683
Final Model Recall: 0.492000013589859
Final Model False Positives per Hour: 1.0619468688964844
################

INFO:root:####
Saving ONNX mode as '/workspace/combs/final_result/Hey_Clãriss_n45000_s50000_w3000.onnx'
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754173542.454543 2825426 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754173542.460989 2825426 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754173542.477807 2825426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754173542.477836 2825426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754173542.477840 2825426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754173542.477843 2825426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.

Model optimizing started ============================================================
Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 14             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 200.6KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Simplifying...
Finish! Here is the difference:
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓
┃            ┃ Original Model ┃ Simplified Model ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩
│ Add        │ 4              │ 4                │
│ Constant   │ 12             │ 12               │
│ Div        │ 2              │ 2                │
│ Flatten    │ 1              │ 1                │
│ Gemm       │ 3              │ 3                │
│ Mul        │ 2              │ 2                │
│ Pow        │ 2              │ 2                │
│ ReduceMean │ 4              │ 4                │
│ Relu       │ 2              │ 2                │
│ Sigmoid    │ 1              │ 1                │
│ Sqrt       │ 2              │ 2                │
│ Sub        │ 2              │ 2                │
│ Model Size │ 201.4KiB       │ 201.4KiB         │
└────────────┴────────────────┴──────────────────┘

Model optimizing complete!

Automatic generation of each OP name started ========================================
Automatic generation of each OP name complete!

Model loaded ========================================================================

Model conversion started ============================================================
INFO: input_op_name: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32

INFO: 2 / 26
INFO: onnx_op_type: Flatten onnx_op_name: /flatten/Flatten
INFO:  input_name.1: onnx____Flatten_0 shape: [1, 16, 96] dtype: float32
INFO:  output_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO: tf_op_type: reshape
INFO:  input.1.tensor: name: onnx____Flatten_0 shape: (1, 16, 96) dtype: <dtype: 'float32'> 
INFO:  input.2.shape: val: [1, 1536] 
INFO:  output.1.output: name: tf.reshape/Reshape:0 shape: (1, 1536) dtype: <dtype: 'float32'> 

INFO: 3 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /layer1/Gemm
INFO:  input_name.1: /flatten/Flatten_output_0 shape: [1, 1536] dtype: float32
INFO:  input_name.2: layer1.weight shape: [32, 1536] dtype: float32
INFO:  input_name.3: layer1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 1536) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1536, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 4 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 5 / 26
INFO: onnx_op_type: Sub onnx_op_name: /layernorm1/Sub
INFO:  input_name.1: /layer1/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_1/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 6 / 26
INFO: onnx_op_type: Pow onnx_op_name: /layernorm1/Pow
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 7 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /layernorm1/ReduceMean_1
INFO:  input_name.1: /layernorm1/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_4/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 8 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add
INFO:  input_name.1: /layernorm1/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: [] dtype: float32
INFO:  output_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_3/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 9 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /layernorm1/Sqrt
INFO:  input_name.1: /layernorm1/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_1/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 10 / 26
INFO: onnx_op_type: Div onnx_op_name: /layernorm1/Div
INFO:  input_name.1: /layernorm1/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 11 / 26
INFO: onnx_op_type: Mul onnx_op_name: /layernorm1/Mul
INFO:  input_name.1: /layernorm1/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.weight shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 12 / 26
INFO: onnx_op_type: Add onnx_op_name: /layernorm1/Add_1
INFO:  input_name.1: /layernorm1/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: layernorm1.bias shape: [32] dtype: float32
INFO:  output_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_10/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 13 / 26
INFO: onnx_op_type: Relu onnx_op_name: /relu1/Relu
INFO:  input_name.1: /layernorm1/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_2/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 14 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /blocks.0/fcn_layer/Gemm
INFO:  input_name.1: /relu1/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.fcn_layer.weight shape: [32, 32] dtype: float32
INFO:  input_name.3: blocks.0.fcn_layer.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (32,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 15 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 16 / 26
INFO: onnx_op_type: Sub onnx_op_name: /blocks.0/layer_norm/Sub
INFO:  input_name.1: /blocks.0/fcn_layer/Gemm_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/ReduceMean_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: subtract
INFO:  input.1.x: name: tf.__operators__.add_1/AddV2:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.reduce_mean_5/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 17 / 26
INFO: onnx_op_type: Pow onnx_op_name: /blocks.0/layer_norm/Pow
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: pow
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 18 / 26
INFO: onnx_op_type: ReduceMean onnx_op_name: /blocks.0/layer_norm/ReduceMean_1
INFO:  input_name.1: /blocks.0/layer_norm/Pow_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: reduce_mean
INFO:  input.1.axis0: val: 1 
INFO:  input.2.input_tensor: name: tf.math.multiply_16/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.3.keepdims: val: True 
INFO:  output.1.output: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 19 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add
INFO:  input_name.1: /blocks.0/layer_norm/ReduceMean_1_output_0 shape: [1, 1] dtype: float32
INFO:  input_name.2: /layernorm1/Constant_1_output_0 shape: () dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.reduce_mean_7/Mean:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: () dtype: float32 
INFO:  output.1.output: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 20 / 26
INFO: onnx_op_type: Sqrt onnx_op_name: /blocks.0/layer_norm/Sqrt
INFO:  input_name.1: /blocks.0/layer_norm/Add_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: sqrt
INFO:  input.1.x: name: tf.math.add_4/Add:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 21 / 26
INFO: onnx_op_type: Div onnx_op_name: /blocks.0/layer_norm/Div
INFO:  input_name.1: /blocks.0/layer_norm/Sub_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: /blocks.0/layer_norm/Sqrt_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: divide
INFO:  input.1.x: name: tf.math.subtract_1/Sub:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: name: tf.math.sqrt_1/Sqrt:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 22 / 26
INFO: onnx_op_type: Mul onnx_op_name: /blocks.0/layer_norm/Mul
INFO:  input_name.1: /blocks.0/layer_norm/Div_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.weight shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: multiply
INFO:  input.1.x: name: tf.math.divide_1/truediv:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 23 / 26
INFO: onnx_op_type: Add onnx_op_name: /blocks.0/layer_norm/Add_1
INFO:  input_name.1: /blocks.0/layer_norm/Mul_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: blocks.0.layer_norm.bias shape: [32] dtype: float32
INFO:  output_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: add
INFO:  input.1.x: name: tf.math.multiply_22/Mul:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 24 / 26
INFO: onnx_op_type: Relu onnx_op_name: /blocks.0/relu/Relu
INFO:  input_name.1: /blocks.0/layer_norm/Add_1_output_0 shape: [1, 32] dtype: float32
INFO:  output_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO: tf_op_type: relu
INFO:  input.1.features: name: tf.math.add_5/Add:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.nn.relu_1/Relu:0 shape: (1, 32) dtype: <dtype: 'float32'> 

INFO: 25 / 26
INFO: onnx_op_type: Gemm onnx_op_name: /last_layer/Gemm
INFO:  input_name.1: /blocks.0/relu/Relu_output_0 shape: [1, 32] dtype: float32
INFO:  input_name.2: last_layer.weight shape: [1, 32] dtype: float32
INFO:  input_name.3: last_layer.bias shape: [1] dtype: float32
INFO:  output_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO: tf_op_type: matmul
INFO:  input.1.x: name: Placeholder:0 shape: (1, 32) dtype: <dtype: 'float32'> 
INFO:  input.2.y: shape: (32, 1) dtype: <dtype: 'float32'> 
INFO:  input.3.z: shape: (1,) dtype: <dtype: 'float32'> 
INFO:  input.4.alpha: val: 1.0 
INFO:  input.5.beta: val: 1.0 
INFO:  output.1.output: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 

INFO: 26 / 26
INFO: onnx_op_type: Sigmoid onnx_op_name: /last_act/Sigmoid
INFO:  input_name.1: /last_layer/Gemm_output_0 shape: [1, 1] dtype: float32
INFO:  output_name.1: 39 shape: [1, 1] dtype: float32
INFO: tf_op_type: sigmoid
INFO:  input.1.x: name: tf.__operators__.add_2/AddV2:0 shape: (1, 1) dtype: <dtype: 'float32'> 
INFO:  output.1.output: name: tf.math.sigmoid/Sigmoid:0 shape: (1, 1) dtype: <dtype: 'float32'> 

saved_model output started ==========================================================
Saved artifact at 'final_result/'. The following endpoints are available:

* Endpoint 'serving_default'
  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')
Output Type:
  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)
Captures:
  125916228158096: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)
  125916230675024: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125916228161360: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  125916228159248: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125916228164240: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  125916228162704: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  125916228161744: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)
  125916228162320: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125916228162128: TensorSpec(shape=(32,), dtype=tf.float32, name=None)
  125916228164816: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125916228163856: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  125916228162512: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)
  125916228163472: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)
  125916228161936: TensorSpec(shape=(), dtype=tf.float32, name=None)
  125916228161552: TensorSpec(shape=(1,), dtype=tf.float32, name=None)
saved_model output complete!
I0000 00:00:1754173547.459834 2825426 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754173547.460257 2825426 single_machine.cc:374] Starting new session
W0000 00:00:1754173547.662767 2825426 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754173547.662813 2825426 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float32 tflite output complete!
I0000 00:00:1754173547.732472 2825426 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
I0000 00:00:1754173547.732853 2825426 single_machine.cc:374] Starting new session
W0000 00:00:1754173547.890432 2825426 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.
W0000 00:00:1754173547.890476 2825426 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.
Float16 tflite output complete!

=== Training combination 5/8 ===
N_samples: 50000, Steps: 30000, Max_negative_weight: 3000
/opt/conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
✓ pt_PT-tugão-medium.onnx already exists, skipping download
✓ pt_PT-tugão-medium.onnx.json already exists, skipping download
Ensuring voice exists: pt_PT-tugão-medium
✓ Voice 'pt_PT-tugão-medium' is ready.
Ensuring voice exists: es_MX-claude-high
✓ Voice 'es_MX-claude-high' is ready.
Ensuring voice exists: pt_BR-cadu-medium
✓ Voice 'pt_BR-cadu-medium' is ready.
Ensuring voice exists: pt_BR-faber-medium
✓ Voice 'pt_BR-faber-medium' is ready.
Ensuring voice exists: pt_PT-rita
✗ Voice 'pt_PT-rita' not found in voices.json. Checking local models...
✓ Found local model: models/pt_PT-rita.onnx
✓ Successfully loaded local model 'pt_PT-rita'
✅ Loaded 5 voice(s)
  0: pt
  1: es-419
  2: pt-br
  3: pt-br
  4: pt
INFO:root:##################################################
Generating positive clips for training
##################################################
INFO:piper_gen:Pre-generating random parameters...
INFO:piper_gen:Starting generation of 5000 samples using GPU...
Generating samples:  69%|█████████████      | 3441/5000 [21:21<00:31, 49.75it/s]